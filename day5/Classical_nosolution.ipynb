{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical methods\n",
    "In this script we evaluate the \"classical\" SVM method for the MNIST database of handwritten digits. It's also meant to become familiar with the 4 dimensional data format used for the deep learning libraries later on.\n",
    "\n",
    "\n",
    "## Loading the data\n",
    "While the original dataset has 70'000 examples of hand written digits, we restrict us here to the first 4000 digits to make an interactive session possible. This is especially necessarry for the for deep learning part we do later.  \n",
    "\n",
    "### Data-Format\n",
    "For the deep learning libraries we will use later all images must be provided in a 4-dimensional array X with the following dimensions: \n",
    "\n",
    "(number of images, number of colors, x, y) \n",
    "\n",
    "and the labels in a vector y of same size. So X[1,0,1,2] would be the image number 1, the color channel 0 and the pixel x = 1 and y=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 1, 28, 28), (4000,), 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "with gzip.open('mnist_4000.pkl.gz', 'rb') as f:\n",
    "    (X,y) = pickle.load(f)\n",
    "PIXELS = len(X[0,0,0,:])\n",
    "X.shape, y.shape, PIXELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Understanding the geometry)\n",
    "Print out the pixel (15,16) of the 0th image and the 0th color channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0584806"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,0,15,16] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (plotting)\n",
    "Plot the 0th image and print out the digit/label stored in the variable *y*. Plotting of a 2-dimnesional matrix XX can be done with \n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(XX, interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x104858290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAADpFJREFUeJzt3X/sXXV9x/Hnd9gFsXWEdWub0lj/wEHaTsjWr2StgWzM\n",
       "QFTE/cHSxKRxakxWlegfQ/bHZFuykCWoWdJgFsBUR6oLjaRmQS1EGbBIi9pSkSpN2qVF+i1OiG2U\n",
       "TNzdH+c039ty73nf3s/33Hu+fT8fyQ3ne9/nnPvp+d4X597v+/wASZIkSZIkSZIkSR12I3AIeB64\n",
       "fcpjkdSii4DDwFpgCbAfuOrsWdYeA3o+fPiYyuM7DPCGQU+OYJYq8Efrn78CvA94bn6Wo5fDs32L\n",
       "bAe2jflyk+D4yji+Mgs6vp2wbsugwm+NucLVwLG+n4/Xz0nqsHED31vQUUiaiHE/0r8ArOn7eQ3V\n",
       "Xv4c2/uml435UpOycdoDCDi+Mhf6+PYC++rpuQ3D5poZc+1vAH4M/Bnw0/rVtnDWd3h6Z3+HlzQh\n",
       "Z77Dvy7f4+7hXwM+BnyT6i/293F22CV10LiBB3i4fkhaJMb9o52kRcjAS4kYeCkRAy8lYuClRAy8\n",
       "lIiBlxIx8FIiJQfeqFWvtbz+X7e8/rYtKVw+51vfPbyUiIGXEjHwUiIGXkrEwEuJGHgpkZy9iYko\n",
       "batFbbO21z9tUdst+ve3/dZenNFxDy8lYuClRAy8lIiBlxIx8FIiBl5KxMBLiSzOZuJERH3e0j52\n",
       "6fqj5X9VuP5I6fJRnz2qR2/daPk3Fq6/1HSi5x5eSsTAS4kYeCkRAy8lYuClRAy8lIiBlxIpbQYe\n",
       "BX4B/IaqMTtbOqDJabsPHi0f9cmj9f+ycPnoV186vr8I6m9uLl/ea64ff7K5fsPm5vrnmstvX/fd\n",
       "xvqBb/5R8wpu+l5zPdROn750rT3geuDn5UOR1LaF+Eg/swDrkDQBpYHvAY8ATwMfKR+OpDaVfqTf\n",
       "BLwI/B6wBzgEPD5f3t4360YW1Vd8aVHZC+yrp+c2DJurNPAv1v99CfgaVaL7Ar+tcPWSRjNL3w71\n",
       "IOxaP2iuko/0lwDL6uk3Ae+qXkhSV5Xs4VdQ7dXPrOcB4FvFI5LUmpLAHwGuXqiBLLxp99lXB/Wo\n",
       "z31Fc/ni4HzvV4PVD/zA1+d0UC91cVB/NWj+XBr02dcG6/+P5vKBR69tnuHuYP3h+6f0dtfj8Ug7\n",
       "KREDLyVi4KVEDLyUiIGXEjHwUiIGXkpkEV+XvvT+6IV99pl3NNf/LuizvhC8/PGg/rOgHvXRo3rU\n",
       "xy8Vbf7jTwUzBG/de1c012ei4yiC31/vcLB8dN376PXbiaZ7eCkRAy8lYuClRAy8lIiBlxIx8FIi\n",
       "Bl5KZBH34SMt37+990xz/dnguuVRH/qVoN52H/1E4fKXB/XwMIpHgnrU517WXO4F18WPrpsfvn43\n",
       "uYeXEjHwUiIGXkrEwEuJGHgpEQMvJWLgpUQu4D582042lx/8n2D53w3qzzeXr4yuWx+sPuyz3xPU\n",
       "g0b/8ei6/O8J6hf6W9Pr0ktqmYGXEjHwUiIGXkrEwEuJGHgpEQMvJTJKs/N+4N1UjecN9XOXAV8F\n",
       "3gIcBW4lPoP7AhOdb/9w4fpfai4f+lhz/Y+DPu8rR4LXj94apY3+LwT1SDS+qM9d2uePlu/mcQSj\n",
       "7OG/CNx4znOfBvYAbwMerX+W1HGjBP5x4OVznrsZ2FFP7wBuWchBSWrHuN/hVwBz9fRc/bOkjluI\n",
       "Lxq9+jHA9r7pjcDsArycpNfbC+yrp+c2DJtr3MDPASup/jKziqFnkmwbc/WSzs8sfTvUg7Br/aC5\n",
       "xv1IvxvYWk9vBR4acz2SJmiUwO8E/gv4A+AY8EHgLuDPgZ8Af1r/LKnjRvlIv2XI8zcs5EC6p/S6\n",
       "9pFTQX3In0VGtTSor13bXD8a9bGjC8tH9dLtW9pnb7tP300eaSclYuClRAy8lIiBlxIx8FIiBl5K\n",
       "xMBLiVyYzcaJiPrI4Q3QA9GvZkdz+dCHm+vrZ5rrR68KXv/JoP6roB4pfWtO57rvo5tO9NzDS4kY\n",
       "eCkRAy8lYuClRAy8lIiBlxIx8FIii7gPHw096pO3fb5724Lxn/h6c335e4P6O5rrP7uyuc5zQf0b\n",
       "QX1xXvd9dNFxGu38+9zDS4kYeCkRAy8lYuClRAy8lIiBlxIx8FIii72Z2aLS89nbFh1H8Hxz+YeP\n",
       "Ndcvva65vvJ3gte/trl84o3B8nuDetdF75/pnK/vHl5KxMBLiRh4KREDLyVi4KVEDLyUiIGXEhml\n",
       "D38/8G7gJLChfu5O4MPAS/XPdxCf4KzzEvVpS8/3/3Zz+ZXofPYPNZdXBuNf+/bmenhd/OjtVnpd\n",
       "/AvTKHv4LwI3nvNcD/gscE39MOzSIjBK4B8HXh7wfHDrEkldU/Id/uPAAeA+4NKFGY6kNo17LP09\n",
       "wD/U0/8I3M3AL3Xb+6Y3ArNjvpykZnuBffX03IZhc40b+JN90/cCQ66YuG3M1Us6P7P07VAPwq71\n",
       "g+Ya9yP9qr7p91cvIKnrRtnD7wSuA5YDx4DPANcDV1P9tf4I8NGWxidpAbX5l/YePNvi6qPzjaM+\n",
       "9KmgHvVxf1m4fFQvPR+/9PWj7XdJUP+T5vKVm5vrS4PVH+811088EKzgzUE9Ol8/qkfHUUTLF12q\n",
       "Yies28KAfHuknZSIgZcSMfBSIgZeSsTAS4kYeCkRAy8lcgFfl77r15WP+rSl58NHfd5I9NaIXv8/\n",
       "g3rQh49cGRxCciK4v314//pS3YyWe3gpEQMvJWLgpUQMvJSIgZcSMfBSIgZeSqSbzcILQun9v0uP\n",
       "I4h+tVH9LUE96nNfXvbykePRDN8P6qXHKSxO7uGlRAy8lIiBlxIx8FIiBl5KxMBLiRh4KRH78ENF\n",
       "53uXLl96Xf3IiqB+U3M5ur97dN34SOlhBqejGaK3dun1CEqPs5gO9/BSIgZeSsTAS4kYeCkRAy8l\n",
       "YuClRAy8lEjUrFwDfAn4faAH/CvwL8BlwFepTpo+CtwKvNLaKDuptJEc9dmj+5dvai4vD85HvzRY\n",
       "ffTPezWoXxzUo/PZTz8TzBDVo+1Xer2AxSnaw/8a+CSwDrgW2AZcBXwa2AO8DXi0/llSx0WBPwHs\n",
       "r6dPU92uYzVwM7Cjfn4HcEsro5O0oM7nO/xa4BrgKarjNufq5+eIj+OU1AGjflFZCuwCbgNOnVPr\n",
       "1Y8BtvdNbwRmz290kka0F9hXT89tGDbXKIFfQhX2LwMPnVkjsJLqI/8q4OTgRbeNNFRJpWbp26Ee\n",
       "hF3rB80VfaSfAe4DfgR8vu/53cDWenor8/8jkNRh0R5+E/ABqh7ID+rn7gDuAv4d+BDzbTlJHRcF\n",
       "/gmGfwq4YYHH0jFt35/9iuby8uC678uD1Ud98qgeCa8L/0RQPxjUlwX1aPu2fb576fn20+nze6Sd\n",
       "lIiBlxIx8FIiBl5KxMBLiRh4KREDLyVyYZ70C5Sf77y6ubz5D8tWH4muLhBelz0Q9tH3BPXngnrU\n",
       "hy7ts19SuHxUL+2zd5N7eCkRAy8lYuClRAy8lIiBlxIx8FIiBl5KZPH24WeCoX9u6GW9AHjPJx5s\n",
       "rB8MTjj/7yebX57HgvqhoF76m9n/i2CGB4J66fn+0XXhS/vkUR982n32bkbLPbyUiIGXEjHwUiIG\n",
       "XkrEwEuJGHgpEQMvJdLNZuEIZnpDbmdX+80/XdRY//tPNa9/9+Hm+l9vvrux/gU+2byCbzSXw/PV\n",
       "j0bnq/88qF8W1Ev71NPuk+fss0fcw0uJGHgpEQMvJWLgpUQMvJSIgZcSiQK/Bvg28CzwQ+AT9fN3\n",
       "UjWOflA/bmxpfJIW0ExQX1k/9gNLge8BtwC3AqeAzzYs26v+PzEdMzT36ZurMDPzWrB8c52oHg0g\n",
       "PB89ev22lfah275/es4+e20nrNvCgHxH/6oT9QOqWx88x/wdGqL/WUjqmPP5Dr8WuAb4bv3zx4ED\n",
       "wH3ApQs7LEltGDXwS4EHgduo9vT3AG8FrgZeBJqPM5XUCaN8UVkC7AL+DXiofu5kX/1e4OuDF93e\n",
       "N70RmD3vAUoaxV5gXz09N/SCjlHgZ6g+sv8I+Hzf86uo9uwA7wcODl58WzxOSQtglr4d6kHYtX7Q\n",
       "XFHgNwEfAJ6har8B/C2wherjfA84Any0cLSSJiAK/BMM/p7/cAtjkdSyRd1sbNIr7Br2elEfN1p/\n",
       "tHzUZ49+NYu9Dx9J3UdvjYfWSokYeCkRAy8lYuClRAy8lIiBlxIx8FIiNivHVrrpur7poz5/18ev\n",
       "QdzDS4kYeCkRAy8lMsHA753cS43F8ZVxfGUmM74JBn5fPMtUOb4yjq/MZMbnR3opkbZ7K9+fnzzd\n",
       "f5WcDnJ8ZRxfmQUd35FhhTYvNf0d4LoW1y9puMeA66c9CEmSJEmL0o3AIeB54PYpj2WQo8xfmbcL\n",
       "Ddv7gTnOvvz3ZcAe4CfAt5ju3X4Gje9OunGD0WE3QO3K9rvgb9B6EXCY6lZVS6huTHnVNAc0wBGq\n",
       "N0RXvJPqtl79gfpn4G/q6duBuyY9qD6DxvcZ4FPTGc5ZVlJdQh2qOyb9mOr91pXtN2x8E9l+k+jD\n",
       "z1IF/ijVpVq/ArxvAq97vrp0c8zHgZfPee5mYEc9vYPqLr7TMmh80I1teIJqpwJn3wC1K9tv2Phg\n",
       "AttvEoFfDRzr+/k48//ArugBjwBPAx+Z8liGWUH1MZr6vyumOJZhunaD0bVUn0Seopvbby0TvkHr\n",
       "JAIf3gm9AzZRbfibqO6P9c7pDifUo3vbtWs3GF1KdU/E24BT59S6sP2mcoPWSQT+Bao/VJyxhmov\n",
       "3yVnjnB6Cfga3bzr5RzV9z+o7u13smHeaTjJfJDuZbrb8MwNUL/M/A1Qu7T9ht2gtfXtN4nAPw1c\n",
       "QfXx5beBvwR2T+B1R3UJsKyefhPwLobeHHOqdgNb6+mtzL9RumJV33TDDUZbN+wGqF3Zfk03aD1j\n",
       "mttvQdxE9dfIw8AdUx7Lud5K9UeU/VRtki6MbyfwU+B/qf7+8UGqLsIjTL+tBK8f318BX6JqbR6g\n",
       "CtO0viNvBv6P6vfZ3+LqyvYbNL6b6M72kyRJkiRJkiRJkiRJknSu/wdpgE6S3fblFQAAAABJRU5E\n",
       "rkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108cac890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y[0])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0,0,:,:], interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (Reshaping)\n",
    "For classification the data must be in a two dimensional array. The rows are the examples and the columns the features. Use `X.reshape((#Number of Rows, #Number of features))` to do the simple unrolling feature extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2d = X.reshape((4000, PIXELS**2))\n",
    "np.shape(X2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just for completness (see if normalization is any good)\n",
    "# It's not needed\n",
    "if False:\n",
    "    Xmean = X2d.mean(axis = 0)\n",
    "    XStd = np.sqrt(X2d.var(axis=0))\n",
    "    X2d = (X2d-Xmean)/(XStd + 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (Classification using a SVM)\n",
    "\n",
    "Use the first 3000 images to train a svm with a linear kernel and parameter C=0.01. Then make predictions on the remaining 1000 images and evalutate the performance (i.e. the percentage of correctly classified images). You may need the following command:\n",
    "\n",
    "```\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=...).fit(...)\n",
    "y_pred = svc.predict(...)\n",
    "np.mean(... == y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X2d[0:3000,:]\n",
    "X_test = X2d[3000:,]\n",
    "y_train = y[0:3000]\n",
    "y_test = y[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=0.01).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92200000000000004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001 number of SV=1661\n",
      "0.916\n",
      "C=0.01 number of SV=1240\n",
      "0.922\n",
      "C=0.1 number of SV=1215\n",
      "0.908\n",
      "C=1 number of SV=1215\n",
      "0.908\n",
      "C=10.0 number of SV=1215\n",
      "0.908\n",
      "C=100.0 number of SV=1215\n",
      "0.908\n"
     ]
    }
   ],
   "source": [
    "# Just for complettness to see which is the best value for C\n",
    "for C in (1e-3, 1e-2, 1e-1, 1, 1e1,1e2):\n",
    "    svc = svm.SVC(kernel='linear', C=C).fit(X_train,y_train)\n",
    "    print('C={0} number of SV={1}'.format(C, len(svc.support_vectors_)))\n",
    "    y_pred = svc.predict(X_test)\n",
    "    print(np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Task 5 (Dimension Reduction)\n",
    "Use a PCA as dimensionreduction, before doing the classification and limit to the first 50 components. Does the result get better? Is the calculation faster? You may need the following command:\n",
    "\n",
    "```\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "pca = RandomizedPCA(..., whiten=True).fit(X_train) #To \"learn the PCA\"\n",
    "X_test_pca = pca.transform(X_test) #To apply the PCA\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Task 5 PCA before classification\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "pca = RandomizedPCA(n_components=50, whiten=True).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92100000000000004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC(kernel='linear', C=0.01).fit(X_train_pca,y_train)\n",
    "y_pred = svc.predict(X_test_pca)\n",
    "np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for completness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001 number of SV=2761\n",
      "0.847\n",
      "C=0.01 number of SV=1721\n",
      "0.913\n",
      "C=0.1 number of SV=1083\n",
      "0.914\n",
      "C=1 number of SV=879\n",
      "0.91\n",
      "C=10.0 number of SV=859\n",
      "0.892\n",
      "C=100.0 number of SV=844\n",
      "0.884\n"
     ]
    }
   ],
   "source": [
    "for C in (1e-3, 1e-2, 1e-1, 1, 1e1,1e2):\n",
    "    svc = svm.SVC(kernel='linear', C=C).fit(X_train_pca,y_train)\n",
    "    print('C={0} number of SV={1}'.format(C, len(svc.support_vectors_)))\n",
    "    y_pred = svc.predict(X_test_pca)\n",
    "    print(np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 LSG\n",
    "\n",
    "A support vector machine (with a linear kernel) can usually deal with many features and the accuracy does not deterioriate. However, the performance (in time) is faster if we do a dimension reduction before the classification. If we would have done for example a kNN classification instead of the SVM we could expect that the accurancy would get better, when using dimension reduction before classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
